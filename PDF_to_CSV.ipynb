{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37944732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "file = \"C:/Users/LENOVO/Downloads/JAYARAM REPORT 1.pdf\"\n",
    "pdfData = tabula.read_pdf(file, pages='1-230', multiple_tables=True)\n",
    "output = tabula.convert_into(file, \"JAYARAM_REPORT_1.csv\", output_format=\"csv\", pages='1-230')\n",
    "print(\"Data has been successfully saved to 'JAYARAM_REPORT_1.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20719eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved successfully.\n",
      "Cleaned data preview:\n",
      "    1.Student Name 2.Father Name 3.Student ID 4.Mother Name  5.Habitation  \\\n",
      "0              NaN           NaN          NaN          None           NaN   \n",
      "1              NaN           NaN   JYOTHI B J          None  XXXXXXXX0046   \n",
      "2    R ANAND KUMAR          None          NaN          None           NaN   \n",
      "3  A H CHINMAY RAM          None  244 092 489          None           NaN   \n",
      "4              NaN           NaN          NaN          None           NaN   \n",
      "\n",
      "  6.Aadhaar UID No.       7.DOA 8.DOB                 9.Sex 10.Caste  \\\n",
      "0              None         NaN  None  4 - OBC(Category 3A)     None   \n",
      "1              None  10/08/2017  None                   NaN     None   \n",
      "2              None         NaN  None                 (N/A)     None   \n",
      "3              None  13/07/2023  None               1 - BOY     None   \n",
      "4              None         NaN  None  4 - OBC(Category 3A)     None   \n",
      "\n",
      "  11.Minority 12.BPL No. 14.Admin RTE 15.Class Studying 16.Previous Class  \\\n",
      "0         NaN       None          NaN              None               NaN   \n",
      "1         NaN       None     Class -1              None               NaN   \n",
      "2         NaN       None          NaN              None               NaN   \n",
      "3   8 - Hindu       None            N              None                 0   \n",
      "4         NaN       None          NaN              None               NaN   \n",
      "\n",
      "  17.Status If 19.Medium and Syllabus 20.Disability  \n",
      "0         None                    NaN          None  \n",
      "1         None                    NaN          None  \n",
      "2         None    99 - Not Applicable          None  \n",
      "3         None                English          None  \n",
      "4         None                    NaN          None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path =  \"C:/Users/LENOVO/Desktop/task/JAYARAM_REPORT_1.csv\" # Update this to your file path\n",
    "try:\n",
    "    # Load the file dynamically and check column count\n",
    "    data = pd.read_csv(file_path, on_bad_lines=\"skip\", header=None)\n",
    "\n",
    "    # Assign generic column names for easier handling\n",
    "    data.columns = [f\"Column{i+1}\" for i in range(data.shape[1])]\n",
    "\n",
    "    # Sort the columns alphabetically\n",
    "    data = data[sorted(data.columns)]\n",
    "\n",
    "    # Remove header-like rows from the dataset\n",
    "    # Assuming real data starts from row 5 onwards based on structure\n",
    "    data = data.iloc[5:].reset_index(drop=True)\n",
    "\n",
    "    # Function to handle safe splitting of columns\n",
    "    def safe_split(column, sep, num_splits):\n",
    "        split_data = column.str.split(sep, expand=True)\n",
    "        # Add missing columns with None\n",
    "        for i in range(num_splits - split_data.shape[1]):\n",
    "            split_data[f\"Extra_{i+1}\"] = None\n",
    "        return split_data.iloc[:, :num_splits]\n",
    "\n",
    "    # Splitting columns based on original script logic\n",
    "    if 'Column2' in data.columns:\n",
    "        data[['1.Student Name', '2.Father Name']] = safe_split(data['Column2'], r'\\s{2,}', 2)\n",
    "\n",
    "    if 'Column3' in data.columns:\n",
    "        data[['3.Student ID', '4.Mother Name']] = safe_split(data['Column3'], ',', 2)\n",
    "\n",
    "    if 'Column4' in data.columns:\n",
    "        data[['5.Habitation', '6.Aadhaar UID No.']] = safe_split(data['Column4'], ',', 2)\n",
    "\n",
    "    if 'Column5' in data.columns:\n",
    "        data[['7.DOA', '8.DOB']] = safe_split(data['Column5'], ',', 2)\n",
    "\n",
    "    if 'Column6' in data.columns:\n",
    "        data[['9.Sex', '10.Caste']] = safe_split(data['Column6'], ',', 2)\n",
    "\n",
    "    if 'Column7' in data.columns:\n",
    "        data[['11.Minority', '12.BPL No.']] = safe_split(data['Column7'], ',', 2)\n",
    "\n",
    "    if 'Column9' in data.columns:\n",
    "        data[['14.Admin RTE', '15.Class Studying']] = safe_split(data['Column9'], ',', 2)\n",
    "\n",
    "    if 'Column10' in data.columns:\n",
    "        data[['16.Previous Class', '17.Status If']] = safe_split(data['Column10'], ',', 2)\n",
    "\n",
    "    if 'Column11' in data.columns:\n",
    "        data[['19.Medium and Syllabus', '20.Disability']] = safe_split(data['Column11'], ',', 2)\n",
    "\n",
    "    # Drop the original merged columns after splitting\n",
    "    columns_to_drop = [col for col in data.columns if col.startswith('Column')]\n",
    "    data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Save the cleaned data\n",
    "    cleaned_file_path =  \"C:/Users/LENOVO/Desktop/task/SORTED_JAYARAM_REPORT_1.csv\"\n",
    "    data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "    # Display cleaned data preview\n",
    "    print(\"Cleaned data saved successfully.\")\n",
    "    print(\"Cleaned data preview:\")\n",
    "    print(data.head())\n",
    "\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079c92ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved successfully.\n",
      "Preview of cleaned data:\n",
      "  Sr. No. Correction   1.Student Name 2.Father Name 3.Student ID  \\\n",
      "0     NaN        NaN              NaN           NaN          NaN   \n",
      "1     NaN        NaN              NaN           NaN   JYOTHI B J   \n",
      "2     NaN        NaN    R ANAND KUMAR          None          NaN   \n",
      "3       2        NaN  A H CHINMAY RAM          None  244 092 489   \n",
      "4     NaN        NaN              NaN           NaN          NaN   \n",
      "\n",
      "  4.Mother Name  5.Habitation 6.Aadhaar UID No.       7.DOA 8.DOB  \\\n",
      "0          None           NaN              None         NaN  None   \n",
      "1          None  XXXXXXXX0046              None  10/08/2017  None   \n",
      "2          None           NaN              None         NaN  None   \n",
      "3          None           NaN              None  13/07/2023  None   \n",
      "4          None           NaN              None         NaN  None   \n",
      "\n",
      "                  9.Sex 10.Caste 11.Minority 12.BPL No. 14.Admin RTE  \\\n",
      "0  4 - OBC(Category 3A)     None         NaN       None          NaN   \n",
      "1                   NaN     None         NaN       None     Class -1   \n",
      "2                 (N/A)     None         NaN       None          NaN   \n",
      "3               1 - BOY     None   8 - Hindu       None            N   \n",
      "4  4 - OBC(Category 3A)     None         NaN       None          NaN   \n",
      "\n",
      "  15.Class Studying 16.Previous Class 17.Status If 19.Medium and Syllabus  \\\n",
      "0              None               NaN         None                    NaN   \n",
      "1              None               NaN         None                    NaN   \n",
      "2              None               NaN         None    99 - Not Applicable   \n",
      "3              None                 0         None                English   \n",
      "4              None               NaN         None                    NaN   \n",
      "\n",
      "  20.Disability  \n",
      "0          None  \n",
      "1          None  \n",
      "2          None  \n",
      "3          None  \n",
      "4          None  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load and process the CSV file\n",
    "def process_csv(file_path, output_path):\n",
    "    try:\n",
    "        # Load the file dynamically, skipping bad lines\n",
    "        data = pd.read_csv(file_path, on_bad_lines=\"skip\", header=None)\n",
    "\n",
    "        # Assign generic column names for easier handling\n",
    "        data.columns = [f\"Column{i+1}\" for i in range(data.shape[1])]\n",
    "\n",
    "        # Retain Column1 as \"Sr. No.\" and the last column as \"Correction\"\n",
    "        column_order = data.columns.tolist()\n",
    "        sr_no_column = \"Column1\"\n",
    "        correction_column = column_order[-1]\n",
    "\n",
    "        # Sort remaining columns excluding \"Sr. No.\" and \"Correction\"\n",
    "        sorted_columns = sorted(column_order[1:-1])  # Exclude Column1 and last column\n",
    "        data = data[[sr_no_column] + sorted_columns + [correction_column]]\n",
    "\n",
    "        # Rename \"Sr. No.\" and \"Correction\"\n",
    "        data.rename(columns={sr_no_column: \"Sr. No.\", correction_column: \"Correction\"}, inplace=True)\n",
    "\n",
    "        # Remove header-like rows from the dataset\n",
    "        # Assuming real data starts from row 5 onwards based on structure\n",
    "        data = data.iloc[5:].reset_index(drop=True)\n",
    "\n",
    "        # Function to handle safe splitting of columns\n",
    "        def safe_split(column, sep, num_splits):\n",
    "            split_data = column.str.split(sep, expand=True)\n",
    "            # Add missing columns with None if split does not result in enough parts\n",
    "            for i in range(num_splits - split_data.shape[1]):\n",
    "                split_data[f\"Extra_{i+1}\"] = None\n",
    "            return split_data.iloc[:, :num_splits]  # Return only the required number of columns\n",
    "\n",
    "        # Splitting columns based on the original logic\n",
    "        if 'Column2' in data.columns:\n",
    "            data[['1.Student Name', '2.Father Name']] = safe_split(data['Column2'], r'\\s{2,}', 2)\n",
    "\n",
    "        if 'Column3' in data.columns:\n",
    "            data[['3.Student ID', '4.Mother Name']] = safe_split(data['Column3'], ',', 2)\n",
    "\n",
    "        if 'Column4' in data.columns:\n",
    "            data[['5.Habitation', '6.Aadhaar UID No.']] = safe_split(data['Column4'], ',', 2)\n",
    "\n",
    "        if 'Column5' in data.columns:\n",
    "            data[['7.DOA', '8.DOB']] = safe_split(data['Column5'], ',', 2)\n",
    "\n",
    "        if 'Column6' in data.columns:\n",
    "            data[['9.Sex', '10.Caste']] = safe_split(data['Column6'], ',', 2)\n",
    "\n",
    "        if 'Column7' in data.columns:\n",
    "            data[['11.Minority', '12.BPL No.']] = safe_split(data['Column7'], ',', 2)\n",
    "\n",
    "        if 'Column9' in data.columns:\n",
    "            data[['14.Admin RTE', '15.Class Studying']] = safe_split(data['Column9'], ',', 2)\n",
    "\n",
    "        if 'Column10' in data.columns:\n",
    "            data[['16.Previous Class', '17.Status If']] = safe_split(data['Column10'], ',', 2)\n",
    "\n",
    "        if 'Column11' in data.columns:\n",
    "            data[['19.Medium and Syllabus', '20.Disability']] = safe_split(data['Column11'], ',', 2)\n",
    "\n",
    "        # Drop the original merged columns after splitting\n",
    "        columns_to_drop = [col for col in data.columns if col.startswith('Column')]\n",
    "        data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "        # Save the cleaned data\n",
    "        data.to_csv(output_path, index=False)\n",
    "\n",
    "        # Display confirmation and a preview of the cleaned data\n",
    "        print(\"Cleaned data saved successfully.\")\n",
    "        print(\"Preview of cleaned data:\")\n",
    "        print(data.head())\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Paths for input CSV and output CSV\n",
    "input_csv_path = \"C:/Users/LENOVO/Desktop/task/JAYARAM_REPORT_1.csv\"  # Update with your file path\n",
    "output_csv_path = \"C:/Users/LENOVO/Desktop/task/SORTED_JAYARAM_REPORT_2.csv\"  # Update with your output file path\n",
    "\n",
    "# Execute the CSV processing\n",
    "process_csv(input_csv_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580447f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
